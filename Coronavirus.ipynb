{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *The completed project can be found in E:\\Virtual Assistant\\corona.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import requests \n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "\n",
    "import speech_recognition as sr\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\ower\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "D:\\Users\\ower\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\ower\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\ower\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "def scrape_table(url):\n",
    "    # Creating soup for each source\n",
    "    soup = BeautifulSoup(requests.get(url).content, 'lxml')\n",
    "\n",
    "    # Getting rows for each table from soup\n",
    "    table_rows = soup.find_all('tr')\n",
    "    \n",
    "    # Getting column names given as the 'th' tag; strip=True means that the tags are removed from the string\n",
    "    column_names = []\n",
    "    for cell in table_rows[0].find_all('th'):\n",
    "        column_names.append(cell.get_text(strip=True))\n",
    "\n",
    "    # Getting cell data in list to later create a DataFrame\n",
    "    each_row = []\n",
    "    for row in table_rows[1:]:\n",
    "        each_row.append([cell.get_text(strip=True) for cell in row.find_all('td')])\n",
    "\n",
    "    # Creating DataFrame from extracted data\n",
    "    df = pd.DataFrame(each_row, columns=column_names)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clean_data(df):\n",
    "    \n",
    "    # Checking for which dataframe is recieved \n",
    "    if 'Name of State / UT' in df:\n",
    "        df = india_df.iloc[:33, :]\n",
    "        df.drop('S. No.', axis=1, inplace=True)\n",
    "        df.set_index('Name of State / UT', inplace=True)\n",
    "        for col in df.columns:\n",
    "            df[col] = df[col].str.extract('(\\d+)').astype(int)\n",
    "        df.sort_values(df.columns[0], ascending=False, inplace=True)\n",
    "        \n",
    "        # Creating recovery_rate to understand more about the closed cases\n",
    "        df['recovery_rate (in percentage)'] = ((df[df.columns[1]]/(df[df.columns[1]]+df[df.columns[2]]))*100).round(2)\n",
    "        \n",
    "        # No idea why this isnt working\n",
    "#        df.rename(columns={df.columns[1]:'Total Cases',\n",
    "#                        df.columns[3]:'Deaths', \n",
    "#                        df.columns[2]:'Total Recovered'}, \n",
    "#                  inplace=True)\n",
    "#        response = requests.get(\"https://api.covid19india.org/state_test_data.json\")\n",
    "#        data = json.loads(response.text)\n",
    "#        data1 = data.get('states_tested_data')\n",
    "#        df['ICU Beds'] = 0\n",
    "#        df['Isolation Beds'] = 0\n",
    "#        df['Total Tests'] = 0\n",
    "#        df['Test positive rate'] = 0\n",
    "#        for x in data1:\n",
    "#            if x.get('state') in df[df.columns[0]].values:\n",
    "#                if x.get('testpositivityrate') != '':\n",
    "#                    df.loc[temp_df[df.columns[0]]==x.get('state'), 'Test positive rate'] = float(x.get('testpositivityrate')[:-1])\n",
    "#                if x.get('totaltested') != '':\n",
    "#                    df.loc[temp_df[df.columns[0]]==x.get('state'), 'Total Tests'] = float(x.get('totaltested'))\n",
    "#                if x.get('numicubeds') != '':\n",
    "#                    df.loc[temp_df[df.columns[0]]==x.get('state'), 'ICU Beds'] = int(x.get('numicubeds'))\n",
    "#                if x.get('numisolationbeds') != '':\n",
    "#                    df.loc[temp_df[df.columns[0]]==x.get('state'), 'Isolation Beds'] = int(x.get('numisolationbeds'))\n",
    "    \n",
    "    elif 'TotalDeaths' in df:\n",
    "        # The reason for not hard coding here below is that\n",
    "        # The website might add on later new countires whose data might not be available now\n",
    "        upper_index = world_df[world_df['Country,Other']=='World'].index[0]\n",
    "        lower_index = world_df[world_df['Country,Other']=='Total:'].index[0]\n",
    "        \n",
    "        # 15 May, website updated their table and added a number column\n",
    "        world_df.drop('#', axis=1, inplace=True)\n",
    "        \n",
    "        # Dropping columns after active cases, this can be changed depending on need for analysis later on\n",
    "        df = world_df.iloc[upper_index:lower_index, :-7]\n",
    "        df['Total Tests'] = world_df.loc[:, 'TotalTests'].iloc[upper_index:lower_index]\n",
    "        df.set_index('Country,Other', inplace=True)\n",
    "        \n",
    "        # Converting alphanumeric data to pure numeric and later to integer type\n",
    "        # this works for all values\n",
    "        for col in df.columns:\n",
    "            df[col] = [''.join(re.findall(r'\\d+', df[col].values[i])) for i in range(len(df[col]))]\n",
    "            df[col] = df[col].replace('', 0)\n",
    "            df[col] = df[col].apply(int)\n",
    "            \n",
    "        df.sort_values('TotalCases', ascending=False, inplace=True)\n",
    "        df['recovery_rate (in percentage)'] = ((df[df.columns[4]]/(df[df.columns[4]]+df[df.columns[2]]))*100).round(2)\n",
    "        df['Positive Rate'] = ((df['TotalCases']/df['Total Tests'])*100).round(2)\n",
    "        df['Positive Rate'].replace(np.inf, 0, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "india_url = 'https://www.mohfw.gov.in/'\n",
    "india_df = scrape_table(india_url)\n",
    "world_url = 'https://www.worldometers.info/coronavirus/'\n",
    "world_df = scrape_table(world_url)\n",
    "\n",
    "india_df_clean = clean_data(india_df)\n",
    "world_df_clean = clean_data(world_df)\n",
    "\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "temp_df = india_df_clean.reset_index()\n",
    "temp_df1 =world_df_clean.reset_index()\n",
    "\n",
    "#Adding Positive Rate \n",
    "#temp_df1['Positive Rate'] = ((temp_df1['TotalCases']/temp_df1['Total Tests'])*100).round(2)\n",
    "#temp_df1.replace(np.inf, 0, inplace=True)\n",
    "\n",
    "\n",
    "temp_df.rename(columns={temp_df.columns[1]:'Total Cases',\n",
    "                        temp_df.columns[3]:'Deaths', \n",
    "                        temp_df.columns[2]:'Total Recovered'}, \n",
    "               inplace=True)\n",
    "response = requests.get(\"https://api.covid19india.org/state_test_data.json\")\n",
    "data = json.loads(response.text)\n",
    "data1 = data.get('states_tested_data')\n",
    "temp_df['ICU Beds'] = 0\n",
    "temp_df['Isolation Beds'] = 0\n",
    "temp_df['Total Tests'] = 0\n",
    "temp_df['Test positive rate'] = 0\n",
    "for x in data1:\n",
    "    if x.get('state') in temp_df[temp_df.columns[0]].values:\n",
    "        if x.get('testpositivityrate') != '':\n",
    "            temp_df.loc[temp_df[temp_df.columns[0]]==x.get('state'), 'Test positive rate'] = float(x.get('testpositivityrate')[:-1])\n",
    "        if x.get('totaltested') != '':\n",
    "            temp_df.loc[temp_df[temp_df.columns[0]]==x.get('state'), 'Total Tests'] = float(x.get('totaltested'))\n",
    "        if x.get('numicubeds') != '':\n",
    "            temp_df.loc[temp_df[temp_df.columns[0]]==x.get('state'), 'ICU Beds'] = int(x.get('numicubeds'))\n",
    "        if x.get('numisolationbeds') != '':\n",
    "            temp_df.loc[temp_df[temp_df.columns[0]]==x.get('state'), 'Isolation Beds'] = int(x.get('numisolationbeds'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Speak method is now defined'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def speak(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "    return text\n",
    "speak('Speak method is now defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f6e571b4356d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#print(get_audio())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mspeak\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'now say something to initiate the microphone'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mspeak\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_audio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-f6e571b4356d>\u001b[0m in \u001b[0;36mget_audio\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRecognizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMicrophone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0msaid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\ower\\Anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mlisten\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    650\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 652\u001b[1;33m                 \u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHUNK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    653\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m  \u001b[1;31m# reached end of the stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m                 \u001b[0mframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\ower\\Anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyaudio_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\ower\\Anaconda3\\lib\\site-packages\\pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_audio():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        audio = r.listen(source)\n",
    "        said = ''\n",
    "        \n",
    "        try:\n",
    "            said = r.recognize_google(audio)\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "    return said.lower()\n",
    "#print(get_audio())\n",
    "speak('now say something to initiate the microphone')\n",
    "speak(get_audio())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'get me total cases in india'\n",
    "def query_df(text):\n",
    "    query_country_or_state = []\n",
    "    text = text.replace('and', '')\n",
    "    text = text.replace('in ', '')\n",
    "    text = text.replace('tamilnadu', 'tamil nadu')\n",
    "    df = temp_df\n",
    "    for state in df[df.columns[0]].values:\n",
    "        for t in text.split():\n",
    "            if t == state.lower():\n",
    "                query_country_or_state.append(state)\n",
    "    if any(query_country_or_state) == False :\n",
    "        df = temp_df1\n",
    "        for country in df[df.columns[0]].values:\n",
    "            for t in text.split():\n",
    "                if t == country.lower():\n",
    "                    query_country_or_state.append(country)\n",
    "    return df.set_index(df.columns[0]).loc[query_country_or_state].reset_index().drop_duplicates()\n",
    "query_df(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'total cases and deaths in india'\n",
    "def query_col(text):\n",
    "    india_column_patterns = {re.compile(\"[\\w\\s]+ cases [\\w\\s]+\") : temp_df.columns[1],\n",
    "                             re.compile(\"[\\w\\s]+ recovered [\\w\\s]+\") : temp_df.columns[2],\n",
    "                             re.compile(\"[\\w\\s]+ deaths [\\w\\s]+\") : temp_df.columns[3],\n",
    "                             re.compile(\"[\\w\\s]+ recovery rate [\\w\\s]+\") : temp_df.columns[4],\n",
    "                             re.compile(\"[\\w\\s]+ tests [\\w\\s]+\") : temp_df.columns[7],\n",
    "                             re.compile(\"[\\w\\s]+ positive rate [\\w\\s]+\") : temp_df.columns[8],}\n",
    "    world_column_patterns = {re.compile(\"[\\w\\s]+ cases [\\w\\s]+\") : temp_df1.columns[1],\n",
    "                             re.compile(\"[\\w\\s]+ recovered [\\w\\s]+\") : temp_df1.columns[5],\n",
    "                             re.compile(\"[\\w\\s]+ deaths [\\w\\s]+\") : temp_df1.columns[3],\n",
    "                             re.compile(\"[\\w\\s]+ recovery rate [\\w\\s]+\") : temp_df1.columns[8],\n",
    "                             re.compile(\"[\\w\\s]+ tests [\\w\\s]+\") : temp_df1.columns[7],\n",
    "                             re.compile(\"[\\w\\s]+ positive rate [\\w\\s]+\") : temp_df1.columns[9],}\n",
    "    india_state = temp_df[temp_df.columns[0]].str.lower().values\n",
    "    col = []\n",
    "    p = india_column_patterns\n",
    "    for t in text.split():\n",
    "        if t in india_state:\n",
    "            p = india_column_patterns\n",
    "            print(t)\n",
    "            pass\n",
    "        else:\n",
    "            p = world_column_patterns\n",
    "    for pattern , column in p.items():\n",
    "        if pattern.match(text):\n",
    "            col.append(column)\n",
    "    return col\n",
    "query_col('what is the positive rate for maharashtra')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "##### This was my initial approach\n",
    "<code>\n",
    "text = 'total cases in gujarat and maharashtra'\n",
    "def india_data(text):\n",
    "    found_column = []\n",
    "    for column in temp_df.columns:\n",
    "        column_temp = (column+'.')[:-1]\n",
    "        if re.findall(f'{column_temp.lower()}', text):\n",
    "            found_column.append(column)\n",
    "    print(found_column)\n",
    "#####print(found[found_column])\n",
    "    \n",
    "    found = pd.DataFrame(columns=found_column)\n",
    "    for x in temp_df['Name of State / UT'].values:\n",
    "        state = (x+'.')[:-1]\n",
    "        if re.findall(f'{state.lower()}', text):\n",
    "            found.append(temp_df[temp_df['Name of State / UT'].str.lower() == state.lower()],)\n",
    "            print(found)\n",
    "    #print(found)\n",
    "    \n",
    "    return found\n",
    "z = india_data(text)\n",
    "print('\\n\\n', z, type(z))\n",
    "#####column = re.findall(f'maharashtra', text)\n",
    "#####state = re.findall(f'maharashtra', text)\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listning\n",
      "\n",
      "\n",
      "Listning\n",
      "\n",
      "\n",
      "Listning\n",
      "\n",
      "\n",
      "Listning\n",
      "stop\n",
      "Exit\n"
     ]
    }
   ],
   "source": [
    "end_phrase = 'stop'\n",
    "speak('now you can ask me')\n",
    "while True:\n",
    "    print('Listning')\n",
    "    text = get_audio()\n",
    "    print(text)\n",
    "    if text:\n",
    "        try:\n",
    "            if text.find(end_phrase) != -1:  # stop loop\n",
    "                print(\"Exit\")\n",
    "                speak('The pleasure was mine')\n",
    "                break\n",
    "            #print(query_df(text))\n",
    "            query_result = query_df(text)[query_col(text)].values\n",
    "            speak(query_result)\n",
    "            print(query_result)\n",
    "            print(query_df(text))\n",
    "        except Exception as e:\n",
    "            speak(str(e))\n",
    "            print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'ut', 'state', 'name'}, {'total', 'cases'}, {'total', 'recovered'}, {'deaths'}, {'percentage', 'recovery', 'rate'}, {'icu', 'beds'}, {'isolation', 'beds'}, {'total', 'tests'}, {'positive', 'test', 'rate'}]\n",
      "defaultdict(<class 'list'>, {'ut': [0], 'state': [0], 'name': [0], 'total': [1, 2, 7], 'cases': [1], 'recovered': [2], 'deaths': [3], 'percentage': [4], 'recovery': [4], 'rate': [4, 8], 'icu': [5], 'beds': [5, 6], 'isolation': [6], 'tests': [7], 'positive': [8], 'test': [8]})\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "columns_tokens_sets = []\n",
    "token_occurence = defaultdict(list)\n",
    "\n",
    "\n",
    "for column in list(temp_df.columns.str.lower()):\n",
    "    word_tokens = word_tokenize(column)\n",
    "    #print(word_tokenize(column))\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    #print(filtered_sentence)\n",
    "    \n",
    "    #print(re.findall('[\\w]+', ' '.join(filtered_sentence)))\n",
    "    #print(set(re.findall('[\\w]+', ' '.join(filtered_sentence))))\n",
    "    columns_tokens_sets.append(set(re.findall('[\\w]+', ' '.join(filtered_sentence))))\n",
    "\n",
    "for ide, columns_tokens_set in enumerate(columns_tokens_sets):\n",
    "    for token in (columns_tokens_set):\n",
    "        token_occurence[token].append(ide)\n",
    "\n",
    "\n",
    "print(columns_tokens_sets)\n",
    "print(token_occurence)\n",
    "#filtered_sentence = [w for w in word_tokens if not w in stop_words] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gujarat', 'maharashtra'] \n",
      " [0. 1. 1. 1. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "text = 'number of total deaths in gujarat and maharashtra'\n",
    "state_list = []\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "counts = np.zeros(len(temp_df.columns),)    \n",
    "splitted = text.split('in')\n",
    "\n",
    "word_tokens = word_tokenize(splitted[0])\n",
    "splitted[0] = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "for word in splitted[0]:\n",
    "    for ide in token_occurence[word]:\n",
    "        counts[ide]+=1\n",
    "\n",
    "word_tokens = word_tokenize(splitted[1])\n",
    "splitted[1] = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "for state in splitted[1]:\n",
    "    state_list.append(state)\n",
    "    \n",
    "print(state_list, '\\n', counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
